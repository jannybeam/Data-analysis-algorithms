{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8439478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966d51cd",
   "metadata": {},
   "source": [
    "ВВОДНЫЕ УСЛОВИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70f6b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 1, 3, 0, 5, 10, 1, 2],\n",
    "              [500, 700, 750, 600, 1450,\n",
    "               800, 1500, 2000, 450, 1000],\n",
    "              [1, 1, 2, 1, 2, 1, 3, 3, 1, 2]], dtype = np.float64)\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "019003b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2617132 , 0.17509907, 1.02794228, 0.21840613, 0.53795688,\n",
       "       0.31862798, 1.20396413, 0.05324898, 0.28336673, 0.91967463])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X.T, y)\n",
    "model.predict(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fdbdb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_std_feat(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3aadec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_st = X.copy()\n",
    "X_st[2, :] = calc_std_feat(X[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f92e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96da703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):                                                      # Исходный код функции\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f90ff7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56505739, 0.54366327, 0.73651677, 0.55438552, 0.63133701,\n",
       "       0.57898984, 0.76922923, 0.5133091 , 0.57037143, 0.7149758 ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=sigmoid(model.predict(X.T))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6d90e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations, alpha=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T))\n",
    "    if i % (iterations / 10) == 0:\n",
    "        print(i, W, err)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ead522",
   "metadata": {},
   "source": [
    "1. Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87d12b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss_mod(y, y_pred):                                                              # Измененная функция\n",
    "    y_pred_res=np.where(y_pred==1, y_pred-1e-07, np.where(y_pred==0, y_pred+1e-07, y_pred))\n",
    "    err = - np.mean(y * np.log(y_pred_res) + (1.0 - y) * np.log(1.0 - y_pred_res))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b30723c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.024785862818215"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1=np.array([0.56505739, 0., 0.73651677, 0.55438552, 1.,\n",
    "       0.57898984, 0.76922923, 0.5133091 , 0., 0.7149758 ])\n",
    "calc_logloss_mod(y, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d737122",
   "metadata": {},
   "source": [
    "2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8429b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations, alpha=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss_mod(y, y_pred) \n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T))\n",
    "    if i % (iterations / 10) == 0:\n",
    "        print(i, W, err)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2f1d059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [ 0.49282757 -0.15007512  0.64748969  1.51727928] 1.2013133809011647\n"
     ]
    }
   ],
   "source": [
    "W = eval_model(X_st, y, iterations=1000, alpha=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3260990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X, y, verbose=False, alpha=1e-4, tol=0.00001): \n",
    "    view_ind = 10**(-np.log10(tol)-2) if -np.log10(tol)-2>=1 else 1 \n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    min_err = float('inf')  \n",
    "    n_iter = 0 \n",
    "    stop_chek = True\n",
    "    errors = []  \n",
    "    while stop_chek:\n",
    "        n_iter += 1\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss_mod(y, y_pred) \n",
    "        errors.append(err)\n",
    "        if min_err - err > tol:  \n",
    "            min_err = err\n",
    "        else:  \n",
    "            print(\n",
    "                f'Stop descent! iteration: {n_iter}, weights: {W}, logloss: {min_err}')\n",
    "            stop_chek = False\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T))\n",
    "        if verbose:\n",
    "            if n_iter % view_ind == 0:\n",
    "                print(n_iter, W, err)\n",
    "    return W, min_err, n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "477426ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [-8.650831   -1.25372329 -1.54901597  7.41955336] 0.28239658432599735\n",
      "2000 [-12.40065236  -1.54519184  -2.73360596  10.40076601] 0.24130322780777833\n",
      "3000 [-15.36100912  -1.79394114  -3.63840883  12.7942367 ] 0.215608798138124\n",
      "4000 [-17.89496779  -2.01191968  -4.40078502  14.84932619] 0.19678626622267767\n",
      "5000 [-20.12312962  -2.20577442  -5.0641727   16.65729995] 0.1822476349304427\n",
      "6000 [-22.11355698  -2.38010899  -5.65216163  18.27197463] 0.17065959157189314\n",
      "Stop descent! iteration: 6204, weights: [-22.49301224  -2.41343975  -5.76381384  18.57970581], logloss: 0.1685880929323425\n"
     ]
    }
   ],
   "source": [
    "W = eval_model(X_st, y, alpha=0.6, tol=0.00001, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1a02b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params(X,y,args):\n",
    "    best_params=[]\n",
    "    for arg in args:\n",
    "        W,err,n_iter = eval_model(X, y, alpha=arg)\n",
    "        best_params.append((arg,err,n_iter))\n",
    "    best_params.sort(key=lambda x:x[1])\n",
    "    print(f'best - alpha: {best_params[0][0]},\\nresults:\\nerr: {best_params[0][1]},\\nn_iter: {best_params[0][2]}')\n",
    "    return best_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "09611627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop descent! iteration: 4, weights: [-0.01512682 -1.44851808  0.75644797  1.06048112], logloss: 0.9360085439942413\n",
      "Stop descent! iteration: 6391, weights: [-20.79292735  -2.26433611  -5.26248927  17.20072759], logloss: 0.17820649249087703\n",
      "Stop descent! iteration: 5853, weights: [-8.53503588 -1.24557698 -1.51126618  7.32961021], logloss: 0.2838539721501477\n",
      "Stop descent! iteration: 6493, weights: [-6.18756485 -1.10137381 -0.7192765   5.56154533], logloss: 0.3198397227902269\n",
      "Stop descent! iteration: 6823, weights: [-2.01966427 -0.97319445  0.84001927  2.78391711], logloss: 0.43337113257078075\n",
      "Stop descent! iteration: 4134, weights: [-0.6636217  -0.82018794  1.11647506  1.7462896 ], logloss: 0.4980620278791868\n",
      "Stop descent! iteration: 3017, weights: [ 0.06153887 -0.68603638  0.85254687  1.2130508 ], logloss: 0.5558287097554773\n",
      "Stop descent! iteration: 3104, weights: [ 0.19306961 -0.69531514  0.74058514  1.21943805], logloss: 0.5765738129341405\n",
      "Stop descent! iteration: 6890, weights: [ 0.30486547 -0.64297726  0.65967984  1.27145631], logloss: 0.608860244923452\n",
      "Stop descent! iteration: 11196, weights: [ 0.32871646 -0.60814204  0.6497502   1.29299115], logloss: 0.6272419108714266\n",
      "Stop descent! iteration: 29779, weights: [ 0.39267294 -0.45708299  0.6408199   1.37066871], logloss: 0.7608933828168414\n",
      "Stop descent! iteration: 2, weights: [ 0.4967122  -0.13827022  0.64768844  1.52302697], logloss: 1.220065627789983\n",
      "Stop descent! iteration: 2, weights: [ 0.49671376 -0.13826548  0.64768852  1.52302928], logloss: 1.220065627789983\n",
      "Stop descent! iteration: 2, weights: [ 0.49671396 -0.13826489  0.64768853  1.52302957], logloss: 1.220065627789983\n",
      "Stop descent! iteration: 2, weights: [ 0.49671411 -0.13826442  0.64768854  1.5230298 ], logloss: 1.220065627789983\n",
      "best - alpha: 0.5,\n",
      "results:\n",
      "err: 0.17820649249087703,\n",
      "n_iter: 6391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 0.17820649249087703, 6391)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas=[1, 0.5,0.1,0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001, 0.000005, 0.000001, 0.0000005, 0.0000001]\n",
    "bp=get_best_params(X_st,y,alphas)\n",
    "bp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00485ada",
   "metadata": {},
   "source": [
    "Лучший результат получаем при a = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68e6c9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop descent! iteration: 5853, weights: [-8.53503588 -1.24557698 -1.51126618  7.32961021], logloss: 0.2838539721501477\n",
      "Stop descent! iteration: 6187, weights: [-12.59825223  -1.5614873   -2.79460722  10.55999424], logloss: 0.23942165779557922\n",
      "Stop descent! iteration: 6534, weights: [-16.06978213  -1.85457135  -3.85261322  13.36879382], logloss: 0.21006752362747183\n",
      "Stop descent! iteration: 6535, weights: [-18.71799582  -2.08333293  -4.64651497  15.51714508], logloss: 0.19120600628315837\n",
      "Stop descent! iteration: 6391, weights: [-20.79292735  -2.26433611  -5.26248927  17.20072759], logloss: 0.17820649249087703\n",
      "Stop descent! iteration: 6204, weights: [-22.49301224  -2.41343975  -5.76381384  18.57970581], logloss: 0.1685880929323425\n",
      "Stop descent! iteration: 6, weights: [ 9.91945996e-04 -8.78773470e-01  8.74063808e-01  1.19348750e+00], logloss: 0.5868163760298956\n",
      "Stop descent! iteration: 4, weights: [ 0.06140228 -1.1126246   0.76192585  1.11769668], logloss: 0.6865501501467717\n",
      "Stop descent! iteration: 4, weights: [ 0.018576   -1.31433745  0.75285106  1.07760698], logloss: 0.8025549653255653\n",
      "best - alpha: 0.6,\n",
      "results:\n",
      "err: 0.1685880929323425,\n",
      "n_iter: 6204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6, 0.1685880929323425, 6204)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas=np.arange(1,10)/10\n",
    "bp=get_best_params(X_st,y,alphas)\n",
    "bp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5145689",
   "metadata": {},
   "source": [
    "Лучший результат получаем при a = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddac3ed",
   "metadata": {},
   "source": [
    "3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1. На вход подаётся W, который уже посчитан функцией eval_model, и X, на выходе — массив y_pred_proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "42c0906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(w, x): \n",
    "    pred_proba = sigmoid(np.dot(w, x))\n",
    "    return pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bc49be40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [-8.650831   -1.25372329 -1.54901597  7.41955336] 0.28239658432599735\n",
      "2000 [-12.40065236  -1.54519184  -2.73360596  10.40076601] 0.24130322780777833\n",
      "3000 [-15.36100912  -1.79394114  -3.63840883  12.7942367 ] 0.215608798138124\n",
      "4000 [-17.89496779  -2.01191968  -4.40078502  14.84932619] 0.19678626622267767\n",
      "5000 [-20.12312962  -2.20577442  -5.0641727   16.65729995] 0.1822476349304427\n",
      "6000 [-22.11355698  -2.38010899  -5.65216163  18.27197463] 0.17065959157189314\n",
      "Stop descent! iteration: 6204, weights: [-22.49301224  -2.41343975  -5.76381384  18.57970581], logloss: 0.1685880929323425\n"
     ]
    }
   ],
   "source": [
    "W,_err,_it = eval_model(X_st, y, alpha=0.6, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463e5489",
   "metadata": {},
   "source": [
    "4. Создайте функцию calc_pred, возвращающую предсказанный класс. На вход подаётся W, который уже посчитан функцией eval_model, и X, на выходе — массив y_pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5f63a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(w,x, prob_lim=0.5):    \n",
    "    pred_proba = sigmoid(np.dot(w, x))\n",
    "    pred=np.zeros_like(pred_proba)\n",
    "    for idx, prob in enumerate(pred_proba):\n",
    "        if prob>prob_lim:\n",
    "            pred[idx]=1\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33a8da54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 0., 0., 1.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=calc_pred(W, X_st)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3819d0da",
   "metadata": {},
   "source": [
    "5. Посчитайте Accuracy, матрицу ошибок, точность и полноту, а также F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "146ca0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42dfcabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_accuracy(real, pred):\n",
    "    all_res=len(real)\n",
    "    trues=0\n",
    "    for i in range(all_res):\n",
    "        trues+=int(real[i]==pred[i])\n",
    "    return trues/all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28a482dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_accuracy(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7767cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_confusion_matrix(real, pred):\n",
    "    n_classes=len(np.unique(real))\n",
    "    all_res=len(real)\n",
    "    conf_matr=np.zeros((n_classes,n_classes), dtype='int')\n",
    "    for i in range(all_res):\n",
    "        conf_matr[int(real[i])][int(pred[i])] += 1\n",
    "    return conf_matr  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aeb7f556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0],\n",
       "       [1, 4]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_confusion_matrix(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "41b89282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_precision(real, pred):\n",
    "    tn, fp, fn, tp = my_confusion_matrix(real, pred).ravel()\n",
    "    return tp/(tp+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e207a2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_precision(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e6f8a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_recall(real, pred):\n",
    "    tn, fp, fn, tp = my_confusion_matrix(real, pred).ravel()\n",
    "    return tp/(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6cd814c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_recall(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d29bd5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_f1(real, pred, beta=1):\n",
    "    return (1+beta**2)*my_precision(real, pred)*my_recall(y,y_pred)/(beta**2*my_precision(real, pred)+my_recall(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "648e8658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.888888888888889"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_f1(y,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3245b700",
   "metadata": {},
   "source": [
    "6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c45c14",
   "metadata": {},
   "source": [
    "Модель логистической регрессии может переобучиться, в связи с тем что используется сигмоида для преобразования в вероятность предсказания линейной модели. Так как сигмоида не имеет максимума и минимума, а только асимптоты, градиентный спуск не может достичь оптимального решения с помощью градиентных шагов доводя веса до все более экстремальных значений, пытаясь достичь нулевых потерь (вероятность этого события увеличивается с увеличением размерности данных). \n",
    "В качестве способа регуляризации можно использовать раннюю остановку работы модели, а так же L1 и L2 регуляризацию."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
